from transformers import AutoTokenizer
import torch

prompt = "France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette."
candidate1 = "The law does not apply to croissants and brioche."
candidate2 = "The law applies to baguettes."

tokenizer = AutoTokenizer.from_pretrained("Snowflake/snowflake-arctic-embed-m")
inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors="pt", padding=True)
labels = torch.tensor(0).unsqueeze(0)